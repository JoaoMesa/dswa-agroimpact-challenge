{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78a0a8f3-befc-45dd-aa27-8e2f1808cae1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mesa/.local/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from scipy.optimize import differential_evolution\n",
    "import joblib\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Carregar dados\n",
    "train = pd.read_csv('../data/train_renomeado.csv')\n",
    "test = pd.read_csv('../data/test_renomeado.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ec9e80d-4b29-41b4-8725-5b24cae08d5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets identificados: 11 colunas\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train = train.rename(columns={'ENTRADAS (v3)': 'Id'})\n",
    "test = test.rename(columns={'ENTRADAS (v3)': 'Id'})\n",
    "\n",
    "target_cols = train.columns[-11:].tolist()\n",
    "print(f\"Targets identificados: {len(target_cols)} colunas\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be8bf72b-318f-48fd-b6a0-d640a4d1d892",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(df):\n",
    "    \"\"\"Função de feature engineering (mantida igual)\"\"\"\n",
    "    df_new = df.copy()\n",
    "\n",
    "    # 1. Tratamento de outliers e transformações\n",
    "    skewed_cols = ['Emissões pesticidas', 'Urea', 'Macronutrientes']\n",
    "    for col in skewed_cols:\n",
    "        if col in df_new.columns:\n",
    "            df_new[col] = np.log1p(np.abs(df_new[col]))\n",
    "\n",
    "    # 2. Flags binárias para features com excesso de zeros\n",
    "    zero_flag_cols = ['Energia da biomassa', 'Energia elétrica (kwh)', \n",
    "                      'Esterco animal (kg)', 'Esterco verde (kg)', \n",
    "                      'Micronutrientes', 'Transformation total, to and from']\n",
    "\n",
    "    for col in zero_flag_cols:\n",
    "        if col in df_new.columns:\n",
    "            df_new[f'flag_{col}'] = (df_new[col] > 0).astype(int)\n",
    "\n",
    "    # 3. Combinação de features correlacionadas\n",
    "    if 'Calcário e gesso' in df_new.columns and 'Ocuppation, total' in df_new.columns:\n",
    "        df_new['intensidade_calcario'] = df_new['Calcário e gesso'] / (df_new['Ocuppation, total'] + 1e-6)\n",
    "\n",
    "    if 'Transformation total, to and from' in df_new.columns and 'Energia da biomassa' in df_new.columns:\n",
    "        df_new['eficiencia_energetica'] = df_new['Transformation total, to and from'] / (df_new['Energia da biomassa'] + 1e-6)\n",
    "\n",
    "    # 4. PCA para features de pesticidas\n",
    "    pesticidas_cols = ['Fungicida, herbicida e pesticida', 'Emissões pesticidas']\n",
    "    if all(col in df_new.columns for col in pesticidas_cols):\n",
    "        pca = PCA(n_components=1)\n",
    "        pesticidas_pca = pca.fit_transform(df_new[pesticidas_cols])\n",
    "        df_new['pesticidas_pca'] = pesticidas_pca\n",
    "\n",
    "    # 5. Criação de índices compostos\n",
    "    nutrientes_cols = ['Macronutrientes', 'Micronutrientes']\n",
    "    if all(col in df_new.columns for col in nutrientes_cols):\n",
    "        df_new['nutrientes_total'] = df_new['Macronutrientes'] + df_new['Micronutrientes']\n",
    "\n",
    "    if 'Urea' in df_new.columns and 'Ammonia e afins' in df_new.columns:\n",
    "        df_new['impacto_fertilizantes'] = df_new['Urea'] + 0.7 * df_new['Ammonia e afins']\n",
    "\n",
    "    # 6. Interações com a cultura (Seed)\n",
    "    if 'Seed' in df_new.columns:\n",
    "        df_new['biomassa_por_seed'] = df_new.groupby('Seed')['Energia da biomassa'].transform('mean')\n",
    "        df_new['calcario_por_seed'] = df_new.groupby('Seed')['Calcário e gesso'].transform('mean')\n",
    "\n",
    "    # 7. Transformações polinomiais para top features\n",
    "    top_features = [\n",
    "        'Transformation total, to and from',\n",
    "        'Energia da biomassa',\n",
    "        'Micronutrientes',\n",
    "        'Esterco animal (kg)',\n",
    "        'Fungicida, herbicida e pesticida'\n",
    "    ]\n",
    "\n",
    "    for col in top_features:\n",
    "        if col in df_new.columns:\n",
    "            df_new[f'{col}_sq'] = df_new[col] ** 2\n",
    "            df_new[f'{col}_sqrt'] = np.sqrt(np.abs(df_new[col]))\n",
    "\n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75424562-932e-4d3d-8e90-dadab9d6fcfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_categorical(train_df, test_df):\n",
    "    \"\"\"Função de encoding categórico (mantida igual)\"\"\"\n",
    "    train_encoded = train_df.copy()\n",
    "    test_encoded = test_df.copy()\n",
    "\n",
    "    if 'Seed' in train_encoded.columns:\n",
    "        # Target Encoding\n",
    "        target_encoder = {}\n",
    "        for target in target_cols:\n",
    "            for seed in train_encoded['Seed'].unique():\n",
    "                mask = (train_encoded['Seed'] == seed)\n",
    "                target_encoder[(seed, target)] = train_encoded.loc[mask, target].mean()\n",
    "\n",
    "        # Aplicar encoding\n",
    "        for col in target_cols:\n",
    "            train_encoded[f'Seed_encoded_{col}'] = train_encoded['Seed'].apply(\n",
    "                lambda x: target_encoder.get((x, col), 0)\n",
    "            )\n",
    "            test_encoded[f'Seed_encoded_{col}'] = test_encoded['Seed'].apply(\n",
    "                lambda x: target_encoder.get((x, col), np.nan)\n",
    "            )\n",
    "\n",
    "            # Preencher valores faltantes\n",
    "            global_mean = train_encoded[col].mean()\n",
    "            test_encoded[f'Seed_encoded_{col}'] = test_encoded[f'Seed_encoded_{col}'].fillna(global_mean)\n",
    "\n",
    "        # Remover coluna original\n",
    "        train_encoded = train_encoded.drop(columns=['Seed'])\n",
    "        test_encoded = test_encoded.drop(columns=['Seed'])\n",
    "\n",
    "    return train_encoded, test_encoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d365aa69-7f2e-4a99-b10d-94018f35c732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessamento dos dados\n",
    "train_featured = create_features(train)\n",
    "test_featured = create_features(test)\n",
    "train_encoded, test_encoded = encode_categorical(train_featured, test_featured)\n",
    "\n",
    "# Preparar dados\n",
    "train_ids = train_encoded['Id']\n",
    "test_ids = test_encoded['Id']\n",
    "\n",
    "X_train = train_encoded.drop(columns=['Id'] + target_cols)\n",
    "y_train = train_encoded[target_cols]\n",
    "X_test = test_encoded.drop(columns=['Id'])\n",
    "\n",
    "# Garantir mesmas colunas no treino e teste\n",
    "for col in X_train.columns:\n",
    "    if col not in X_test.columns:\n",
    "        X_test[col] = 0\n",
    "X_test = X_test[X_train.columns]\n",
    "\n",
    "# Normalização\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5821532c-a720-43f2-a78e-38f8b29bc67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Garantir mesmas colunas no treino e teste\n",
    "for col in X_train.columns:\n",
    "    if col not in X_test.columns:\n",
    "        X_test[col] = 0\n",
    "X_test = X_test[X_train.columns]\n",
    "\n",
    "# Normalização\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77f2c9c4-eb90-4a28-834f-b98792532b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treinando baseline para comparação...\n"
     ]
    }
   ],
   "source": [
    "# ==================== BASELINE PARA COMPARAÇÃO ====================\n",
    "\n",
    "print(\"Treinando baseline para comparação...\")\n",
    "\n",
    "baseline_models = {\n",
    "    \"RandomForest\": MultiOutputRegressor(\n",
    "        RandomForestRegressor(\n",
    "            n_estimators=300,\n",
    "            max_depth=10,\n",
    "            min_samples_split=5,\n",
    "            max_features=0.8,\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "    ),\n",
    "    \"XGBoost\": MultiOutputRegressor(\n",
    "        XGBRegressor(\n",
    "            n_estimators=500,\n",
    "            learning_rate=0.05,\n",
    "            max_depth=6,\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.8,\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "    ),\n",
    "    \"SVR\": MultiOutputRegressor(\n",
    "        SVR(C=3.0, epsilon=0.1, kernel='rbf')\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f4ef7b6-6a74-4357-9c18-8f0cc5a2cb3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest Baseline MSE: 0.22349\n",
      "XGBoost Baseline MSE: 0.22719\n",
      "SVR Baseline MSE: 0.38741\n",
      "\n",
      "Melhor baseline MSE: 0.22349\n"
     ]
    }
   ],
   "source": [
    "# Avaliar baseline\n",
    "baseline_scores = {}\n",
    "kf = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "for name, model in baseline_models.items():\n",
    "    scores = []\n",
    "    for train_idx, val_idx in kf.split(X_train_scaled):\n",
    "        X_tr, X_val = X_train_scaled[train_idx], X_train_scaled[val_idx]\n",
    "        y_tr, y_val = y_train.values[train_idx], y_train.values[val_idx]\n",
    "        \n",
    "        model.fit(X_tr, y_tr)\n",
    "        y_pred = model.predict(X_val)\n",
    "        scores.append(mean_squared_error(y_val, y_pred))\n",
    "    \n",
    "    baseline_scores[name] = np.mean(scores)\n",
    "    print(f\"{name} Baseline MSE: {baseline_scores[name]:.5f}\")\n",
    "\n",
    "best_baseline_score = min(baseline_scores.values())\n",
    "print(f\"\\nMelhor baseline MSE: {best_baseline_score:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d37d6f79-5383-4d88-979f-781d76d49846",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ==================== OPTUNA OPTIMIZATION - VERSÃO CONSERVADORA ====================\n",
    "\n",
    "def create_optimized_model(trial, model_type):\n",
    "    \"\"\"Cria modelo com otimização conservadora próxima aos valores baseline\"\"\"\n",
    "    \n",
    "    if model_type == 'RandomForest':\n",
    "        params = {\n",
    "            'n_estimators': trial.suggest_int('rf_n_estimators', 200, 600, step=50),\n",
    "            'max_depth': trial.suggest_int('rf_max_depth', 8, 15),\n",
    "            'min_samples_split': trial.suggest_int('rf_min_samples_split', 3, 10),\n",
    "            'min_samples_leaf': trial.suggest_int('rf_min_samples_leaf', 1, 5),\n",
    "            'max_features': trial.suggest_float('rf_max_features', 0.6, 0.9),\n",
    "            'random_state': 42,\n",
    "            'n_jobs': -1\n",
    "        }\n",
    "        return MultiOutputRegressor(RandomForestRegressor(**params))\n",
    "    \n",
    "    elif model_type == 'XGBoost':\n",
    "        params = {\n",
    "            'n_estimators': trial.suggest_int('xgb_n_estimators', 300, 800, step=50),\n",
    "            'learning_rate': trial.suggest_float('xgb_learning_rate', 0.03, 0.15),\n",
    "            'max_depth': trial.suggest_int('xgb_max_depth', 4, 10),\n",
    "            'subsample': trial.suggest_float('xgb_subsample', 0.7, 0.9),\n",
    "            'colsample_bytree': trial.suggest_float('xgb_colsample_bytree', 0.7, 0.9),\n",
    "            'reg_alpha': trial.suggest_float('xgb_reg_alpha', 0.0, 1.0),\n",
    "            'reg_lambda': trial.suggest_float('xgb_reg_lambda', 0.0, 1.0),\n",
    "            'random_state': 42,\n",
    "            'n_jobs': -1\n",
    "        }\n",
    "        return MultiOutputRegressor(XGBRegressor(**params))\n",
    "    \n",
    "    elif model_type == 'SVR':\n",
    "        params = {\n",
    "            'C': trial.suggest_float('svr_C', 1.0, 10.0),\n",
    "            'epsilon': trial.suggest_float('svr_epsilon', 0.05, 0.3),\n",
    "            'kernel': trial.suggest_categorical('svr_kernel', ['rbf', 'poly']),\n",
    "        }\n",
    "        if params['kernel'] == 'poly':\n",
    "            params['degree'] = trial.suggest_int('svr_degree', 2, 4)\n",
    "        return MultiOutputRegressor(SVR(**params))\n",
    "\n",
    "def conservative_objective(trial):\n",
    "    \"\"\"Função objetivo conservadora com early stopping baseado no baseline\"\"\"\n",
    "    \n",
    "    model_type = trial.suggest_categorical('model_type', ['RandomForest', 'XGBoost', 'SVR'])\n",
    "    model = create_optimized_model(trial, model_type)\n",
    "    \n",
    "    # Cross-validation mais rápido\n",
    "    kf = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    cv_scores = []\n",
    "    \n",
    "    for train_idx, val_idx in kf.split(X_train_scaled):\n",
    "        X_tr, X_val = X_train_scaled[train_idx], X_train_scaled[val_idx]\n",
    "        y_tr, y_val = y_train.values[train_idx], y_train.values[val_idx]\n",
    "        \n",
    "        model.fit(X_tr, y_tr)\n",
    "        y_pred = model.predict(X_val)\n",
    "        mse = mean_squared_error(y_val, y_pred)\n",
    "        cv_scores.append(mse)\n",
    "        \n",
    "        # Early stopping se muito pior que o baseline\n",
    "        current_avg = np.mean(cv_scores)\n",
    "        if current_avg > best_baseline_score * 3:  # Se 3x pior que baseline, parar\n",
    "            break\n",
    "    \n",
    "    return np.mean(cv_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd45b343-1b9e-4e12-9a30-d3a0bcc46ab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-31 11:47:16,065] A new study created in memory with name: no-name-94027231-b7ce-498c-8abd-56c20e548914\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iniciando otimização conservadora com Optuna...\n"
     ]
    }
   ],
   "source": [
    "# ==================== EXECUTAR OTIMIZAÇÃO CONSERVADORA ====================\n",
    "\n",
    "print(\"\\nIniciando otimização conservadora com Optuna...\")\n",
    "\n",
    "study = optuna.create_study(\n",
    "    direction='minimize',\n",
    "    sampler=TPESampler(seed=42, n_startup_trials=10),\n",
    "    pruner=optuna.pruners.MedianPruner(\n",
    "        n_startup_trials=5, \n",
    "        n_warmup_steps=5, \n",
    "        interval_steps=1\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a25427cd-7ac7-4469-9505-eca23a7be5aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-31 11:47:31,436] Trial 0 finished with value: 0.22886881910062126 and parameters: {'model_type': 'XGBoost', 'xgb_n_estimators': 600, 'xgb_learning_rate': 0.04872223685309238, 'xgb_max_depth': 5, 'xgb_subsample': 0.7116167224336398, 'xgb_colsample_bytree': 0.8732352291549871, 'xgb_reg_alpha': 0.6011150117432088, 'xgb_reg_lambda': 0.7080725777960455}. Best is trial 0 with value: 0.22886881910062126.\n",
      "[I 2025-07-31 11:47:40,827] Trial 1 finished with value: 0.23954259723779173 and parameters: {'model_type': 'XGBoost', 'xgb_n_estimators': 400, 'xgb_learning_rate': 0.051818996064852074, 'xgb_max_depth': 5, 'xgb_subsample': 0.7608484485919075, 'xgb_colsample_bytree': 0.8049512863264475, 'xgb_reg_alpha': 0.43194501864211576, 'xgb_reg_lambda': 0.2912291401980419}. Best is trial 0 with value: 0.22886881910062126.\n",
      "[I 2025-07-31 11:48:03,846] Trial 2 finished with value: 0.2369299115424283 and parameters: {'model_type': 'RandomForest', 'rf_n_estimators': 350, 'rf_max_depth': 11, 'rf_min_samples_split': 9, 'rf_min_samples_leaf': 1, 'rf_max_features': 0.7542703315240835}. Best is trial 0 with value: 0.22886881910062126.\n",
      "[I 2025-07-31 11:48:03,975] Trial 3 finished with value: 4.862309497159442 and parameters: {'model_type': 'SVR', 'svr_C': 2.5347171131856236, 'svr_epsilon': 0.06626289824631988, 'svr_kernel': 'poly', 'svr_degree': 4}. Best is trial 0 with value: 0.22886881910062126.\n",
      "[I 2025-07-31 11:48:04,241] Trial 4 finished with value: 0.3363159462403033 and parameters: {'model_type': 'SVR', 'svr_C': 4.961372443656412, 'svr_epsilon': 0.08050955871119471, 'svr_kernel': 'rbf'}. Best is trial 0 with value: 0.22886881910062126.\n",
      "[I 2025-07-31 11:48:25,837] Trial 5 finished with value: 0.22494895734109885 and parameters: {'model_type': 'RandomForest', 'rf_n_estimators': 300, 'rf_max_depth': 12, 'rf_min_samples_split': 7, 'rf_min_samples_leaf': 1, 'rf_max_features': 0.8908753883293676}. Best is trial 5 with value: 0.22494895734109885.\n",
      "[I 2025-07-31 11:48:34,270] Trial 6 finished with value: 0.24659098422759454 and parameters: {'model_type': 'XGBoost', 'xgb_n_estimators': 600, 'xgb_learning_rate': 0.140624908202774, 'xgb_max_depth': 4, 'xgb_subsample': 0.739196572483829, 'xgb_colsample_bytree': 0.7090454577821076, 'xgb_reg_alpha': 0.32533033076326434, 'xgb_reg_lambda': 0.388677289689482}. Best is trial 5 with value: 0.22494895734109885.\n",
      "[I 2025-07-31 11:48:40,453] Trial 7 finished with value: 0.2180999717401615 and parameters: {'model_type': 'XGBoost', 'xgb_n_estimators': 450, 'xgb_learning_rate': 0.09512352997898982, 'xgb_max_depth': 4, 'xgb_subsample': 0.8604393961508079, 'xgb_colsample_bytree': 0.7149101287359542, 'xgb_reg_alpha': 0.9868869366005173, 'xgb_reg_lambda': 0.7722447692966574}. Best is trial 7 with value: 0.2180999717401615.\n",
      "[I 2025-07-31 11:48:40,649] Trial 8 finished with value: 0.3262116395090177 and parameters: {'model_type': 'SVR', 'svr_C': 7.361716094628554, 'svr_epsilon': 0.23225179201024682, 'svr_kernel': 'rbf'}. Best is trial 7 with value: 0.2180999717401615.\n",
      "[I 2025-07-31 11:48:41,062] Trial 9 finished with value: 0.4636029497366498 and parameters: {'model_type': 'SVR', 'svr_C': 6.609683141448022, 'svr_epsilon': 0.13272450621316229, 'svr_kernel': 'poly', 'svr_degree': 2}. Best is trial 7 with value: 0.2180999717401615.\n",
      "[I 2025-07-31 11:48:48,091] Trial 10 finished with value: 0.24063157647587982 and parameters: {'model_type': 'XGBoost', 'xgb_n_estimators': 300, 'xgb_learning_rate': 0.1135341364029985, 'xgb_max_depth': 10, 'xgb_subsample': 0.8800473029197429, 'xgb_colsample_bytree': 0.7077450399922366, 'xgb_reg_alpha': 0.9730377607696247, 'xgb_reg_lambda': 0.9704638325621302}. Best is trial 7 with value: 0.2180999717401615.\n",
      "[I 2025-07-31 11:49:04,078] Trial 11 finished with value: 0.2183235574815555 and parameters: {'model_type': 'RandomForest', 'rf_n_estimators': 200, 'rf_max_depth': 15, 'rf_min_samples_split': 4, 'rf_min_samples_leaf': 1, 'rf_max_features': 0.8975850427781378}. Best is trial 7 with value: 0.2180999717401615.\n",
      "[I 2025-07-31 11:49:42,246] Trial 12 finished with value: 0.2828594254035719 and parameters: {'model_type': 'RandomForest', 'rf_n_estimators': 600, 'rf_max_depth': 15, 'rf_min_samples_split': 3, 'rf_min_samples_leaf': 5, 'rf_max_features': 0.8846381727839748}. Best is trial 7 with value: 0.2180999717401615.\n",
      "[I 2025-07-31 11:49:54,443] Trial 13 finished with value: 0.2550158470474971 and parameters: {'model_type': 'RandomForest', 'rf_n_estimators': 200, 'rf_max_depth': 15, 'rf_min_samples_split': 3, 'rf_min_samples_leaf': 3, 'rf_max_features': 0.6100757654803415}. Best is trial 7 with value: 0.2180999717401615.\n",
      "[I 2025-07-31 11:50:25,298] Trial 14 finished with value: 0.2465895489555455 and parameters: {'model_type': 'RandomForest', 'rf_n_estimators': 500, 'rf_max_depth': 8, 'rf_min_samples_split': 5, 'rf_min_samples_leaf': 3, 'rf_max_features': 0.7818308023649239}. Best is trial 7 with value: 0.2180999717401615.\n",
      "[I 2025-07-31 11:50:36,555] Trial 15 finished with value: 0.24045769618338664 and parameters: {'model_type': 'XGBoost', 'xgb_n_estimators': 800, 'xgb_learning_rate': 0.08885942040596057, 'xgb_max_depth': 8, 'xgb_subsample': 0.8587188815375555, 'xgb_colsample_bytree': 0.7782346500507136, 'xgb_reg_alpha': 0.9908417552872778, 'xgb_reg_lambda': 0.005679962534051453}. Best is trial 7 with value: 0.2180999717401615.\n",
      "[I 2025-07-31 11:50:49,295] Trial 16 finished with value: 0.22286047501480524 and parameters: {'model_type': 'XGBoost', 'xgb_n_estimators': 450, 'xgb_learning_rate': 0.08823722354369543, 'xgb_max_depth': 7, 'xgb_subsample': 0.8183796160767343, 'xgb_colsample_bytree': 0.7700071591147374, 'xgb_reg_alpha': 0.08419622745238242, 'xgb_reg_lambda': 0.7946453641120887}. Best is trial 7 with value: 0.2180999717401615.\n",
      "[I 2025-07-31 11:51:02,104] Trial 17 finished with value: 0.23729409371621502 and parameters: {'model_type': 'RandomForest', 'rf_n_estimators': 200, 'rf_max_depth': 13, 'rf_min_samples_split': 6, 'rf_min_samples_leaf': 2, 'rf_max_features': 0.6389321011106691}. Best is trial 7 with value: 0.2180999717401615.\n",
      "[I 2025-07-31 11:51:29,879] Trial 18 finished with value: 0.28386850105014405 and parameters: {'model_type': 'RandomForest', 'rf_n_estimators': 450, 'rf_max_depth': 9, 'rf_min_samples_split': 10, 'rf_min_samples_leaf': 5, 'rf_max_features': 0.8217838736607536}. Best is trial 7 with value: 0.2180999717401615.\n",
      "[I 2025-07-31 11:51:40,054] Trial 19 finished with value: 0.23073436622076424 and parameters: {'model_type': 'XGBoost', 'xgb_n_estimators': 750, 'xgb_learning_rate': 0.11702958753295234, 'xgb_max_depth': 7, 'xgb_subsample': 0.821791656079921, 'xgb_colsample_bytree': 0.8397015415194405, 'xgb_reg_alpha': 0.6872511320877258, 'xgb_reg_lambda': 0.6244643476803539}. Best is trial 7 with value: 0.2180999717401615.\n",
      "[I 2025-07-31 11:51:47,032] Trial 20 finished with value: 0.22041830577969868 and parameters: {'model_type': 'XGBoost', 'xgb_n_estimators': 500, 'xgb_learning_rate': 0.06978135820439002, 'xgb_max_depth': 4, 'xgb_subsample': 0.8996068554991924, 'xgb_colsample_bytree': 0.74102198863023, 'xgb_reg_alpha': 0.7929013874739077, 'xgb_reg_lambda': 0.9412499173366431}. Best is trial 7 with value: 0.2180999717401615.\n",
      "[I 2025-07-31 11:51:54,221] Trial 21 finished with value: 0.22032819516006544 and parameters: {'model_type': 'XGBoost', 'xgb_n_estimators': 500, 'xgb_learning_rate': 0.06666171821898632, 'xgb_max_depth': 4, 'xgb_subsample': 0.8973583801234268, 'xgb_colsample_bytree': 0.741582770987373, 'xgb_reg_alpha': 0.7828290731668657, 'xgb_reg_lambda': 0.9273138858504454}. Best is trial 7 with value: 0.2180999717401615.\n",
      "[I 2025-07-31 11:52:02,228] Trial 22 finished with value: 0.2200477769200165 and parameters: {'model_type': 'XGBoost', 'xgb_n_estimators': 350, 'xgb_learning_rate': 0.06856853867020221, 'xgb_max_depth': 5, 'xgb_subsample': 0.8547218306009439, 'xgb_colsample_bytree': 0.7413291512162876, 'xgb_reg_alpha': 0.8181320251884409, 'xgb_reg_lambda': 0.8247849531879676}. Best is trial 7 with value: 0.2180999717401615.\n",
      "[I 2025-07-31 11:52:13,981] Trial 23 finished with value: 0.22820667756399313 and parameters: {'model_type': 'XGBoost', 'xgb_n_estimators': 300, 'xgb_learning_rate': 0.03180254539508244, 'xgb_max_depth': 6, 'xgb_subsample': 0.8468782133178641, 'xgb_colsample_bytree': 0.740573966134899, 'xgb_reg_alpha': 0.872525891257444, 'xgb_reg_lambda': 0.5796351731166249}. Best is trial 7 with value: 0.2180999717401615.\n",
      "[I 2025-07-31 11:52:21,771] Trial 24 finished with value: 0.22540163490540568 and parameters: {'model_type': 'XGBoost', 'xgb_n_estimators': 400, 'xgb_learning_rate': 0.10983311382874653, 'xgb_max_depth': 5, 'xgb_subsample': 0.7951698959842429, 'xgb_colsample_bytree': 0.7016932132746578, 'xgb_reg_alpha': 0.5566424399667922, 'xgb_reg_lambda': 0.8045678801019253}. Best is trial 7 with value: 0.2180999717401615.\n",
      "[I 2025-07-31 11:52:41,677] Trial 25 finished with value: 0.2503694101140688 and parameters: {'model_type': 'RandomForest', 'rf_n_estimators': 300, 'rf_max_depth': 13, 'rf_min_samples_split': 5, 'rf_min_samples_leaf': 3, 'rf_max_features': 0.6890340490055629}. Best is trial 7 with value: 0.2180999717401615.\n",
      "[I 2025-07-31 11:52:50,684] Trial 26 finished with value: 0.24287249876566733 and parameters: {'model_type': 'XGBoost', 'xgb_n_estimators': 350, 'xgb_learning_rate': 0.07383263443716838, 'xgb_max_depth': 6, 'xgb_subsample': 0.8494175198821834, 'xgb_colsample_bytree': 0.7725682175593496, 'xgb_reg_alpha': 0.8873817634487715, 'xgb_reg_lambda': 0.41039698671331026}. Best is trial 7 with value: 0.2180999717401615.\n",
      "[I 2025-07-31 11:53:03,702] Trial 27 finished with value: 0.22247284399284328 and parameters: {'model_type': 'XGBoost', 'xgb_n_estimators': 550, 'xgb_learning_rate': 0.09742808146575856, 'xgb_max_depth': 9, 'xgb_subsample': 0.7924485585222518, 'xgb_colsample_bytree': 0.8014122001617542, 'xgb_reg_alpha': 0.7118296984141755, 'xgb_reg_lambda': 0.7745625213240863}. Best is trial 7 with value: 0.2180999717401615.\n",
      "[I 2025-07-31 11:53:03,994] Trial 28 finished with value: 0.53914672102574 and parameters: {'model_type': 'SVR', 'svr_C': 9.523970153784813, 'svr_epsilon': 0.2913356981442301, 'svr_kernel': 'poly', 'svr_degree': 2}. Best is trial 7 with value: 0.2180999717401615.\n",
      "[I 2025-07-31 11:53:21,178] Trial 29 finished with value: 0.22481920486203774 and parameters: {'model_type': 'RandomForest', 'rf_n_estimators': 200, 'rf_max_depth': 10, 'rf_min_samples_split': 4, 'rf_min_samples_leaf': 2, 'rf_max_features': 0.8198735384140649}. Best is trial 7 with value: 0.2180999717401615.\n",
      "[I 2025-07-31 11:53:31,655] Trial 30 finished with value: 0.231172063134048 and parameters: {'model_type': 'XGBoost', 'xgb_n_estimators': 400, 'xgb_learning_rate': 0.13128546058035934, 'xgb_max_depth': 6, 'xgb_subsample': 0.8647003053441531, 'xgb_colsample_bytree': 0.7310290819616043, 'xgb_reg_alpha': 0.3391267731857167, 'xgb_reg_lambda': 0.6154208210555888}. Best is trial 7 with value: 0.2180999717401615.\n",
      "[I 2025-07-31 11:53:40,632] Trial 31 finished with value: 0.22002673005686027 and parameters: {'model_type': 'XGBoost', 'xgb_n_estimators': 500, 'xgb_learning_rate': 0.06815257672212464, 'xgb_max_depth': 4, 'xgb_subsample': 0.8982681057083478, 'xgb_colsample_bytree': 0.7463845302031459, 'xgb_reg_alpha': 0.8036822925013718, 'xgb_reg_lambda': 0.8702028819584412}. Best is trial 7 with value: 0.2180999717401615.\n",
      "[I 2025-07-31 11:53:48,422] Trial 32 finished with value: 0.22259436156149195 and parameters: {'model_type': 'XGBoost', 'xgb_n_estimators': 500, 'xgb_learning_rate': 0.07859075229214404, 'xgb_max_depth': 4, 'xgb_subsample': 0.8749996252917913, 'xgb_colsample_bytree': 0.7259817569158197, 'xgb_reg_alpha': 0.870007295966163, 'xgb_reg_lambda': 0.8711588683273461}. Best is trial 7 with value: 0.2180999717401615.\n",
      "[I 2025-07-31 11:53:59,508] Trial 33 finished with value: 0.2224355316551819 and parameters: {'model_type': 'XGBoost', 'xgb_n_estimators': 650, 'xgb_learning_rate': 0.05619298805576684, 'xgb_max_depth': 5, 'xgb_subsample': 0.8340542122204527, 'xgb_colsample_bytree': 0.7591761081578559, 'xgb_reg_alpha': 0.9943229222075939, 'xgb_reg_lambda': 0.7093923629483728}. Best is trial 7 with value: 0.2180999717401615.\n",
      "[I 2025-07-31 11:54:05,565] Trial 34 finished with value: 0.22270194504776356 and parameters: {'model_type': 'XGBoost', 'xgb_n_estimators': 450, 'xgb_learning_rate': 0.09876146358146091, 'xgb_max_depth': 4, 'xgb_subsample': 0.8833027081990089, 'xgb_colsample_bytree': 0.7200661093865663, 'xgb_reg_alpha': 0.6747373048802197, 'xgb_reg_lambda': 0.8612575321909118}. Best is trial 7 with value: 0.2180999717401615.\n",
      "[I 2025-07-31 11:54:14,032] Trial 35 finished with value: 0.22513333377389963 and parameters: {'model_type': 'XGBoost', 'xgb_n_estimators': 350, 'xgb_learning_rate': 0.03658211470947774, 'xgb_max_depth': 5, 'xgb_subsample': 0.8437660802807134, 'xgb_colsample_bytree': 0.7552341002275881, 'xgb_reg_alpha': 0.7958174597890292, 'xgb_reg_lambda': 0.7060322537203905}. Best is trial 7 with value: 0.2180999717401615.\n",
      "[I 2025-07-31 11:54:20,444] Trial 36 finished with value: 0.2139852837704128 and parameters: {'model_type': 'XGBoost', 'xgb_n_estimators': 450, 'xgb_learning_rate': 0.08103217560131955, 'xgb_max_depth': 4, 'xgb_subsample': 0.8720013833374708, 'xgb_colsample_bytree': 0.8231467392024262, 'xgb_reg_alpha': 0.8697317278068769, 'xgb_reg_lambda': 0.9867693313538161}. Best is trial 36 with value: 0.2139852837704128.\n",
      "[I 2025-07-31 11:54:20,639] Trial 37 finished with value: 0.4835722553046047 and parameters: {'model_type': 'SVR', 'svr_C': 1.3244498078073006, 'svr_epsilon': 0.18642907580037077, 'svr_kernel': 'rbf'}. Best is trial 36 with value: 0.2139852837704128.\n",
      "[I 2025-07-31 11:54:53,531] Trial 38 finished with value: 0.2703369199748224 and parameters: {'model_type': 'RandomForest', 'rf_n_estimators': 550, 'rf_max_depth': 14, 'rf_min_samples_split': 8, 'rf_min_samples_leaf': 4, 'rf_max_features': 0.6855331073257482}. Best is trial 36 with value: 0.2139852837704128.\n",
      "[I 2025-07-31 11:55:00,516] Trial 39 finished with value: 0.21800102221232218 and parameters: {'model_type': 'XGBoost', 'xgb_n_estimators': 550, 'xgb_learning_rate': 0.08305717918387648, 'xgb_max_depth': 4, 'xgb_subsample': 0.887142959126134, 'xgb_colsample_bytree': 0.8397231830347572, 'xgb_reg_alpha': 0.9262292862176614, 'xgb_reg_lambda': 0.9990443852008793}. Best is trial 36 with value: 0.2139852837704128.\n",
      "[I 2025-07-31 11:55:00,619] Trial 40 finished with value: 8.525340532266416 and parameters: {'model_type': 'SVR', 'svr_C': 9.737366572687456, 'svr_epsilon': 0.2983096715966263, 'svr_kernel': 'poly', 'svr_degree': 4}. Best is trial 36 with value: 0.2139852837704128.\n",
      "[I 2025-07-31 11:55:07,594] Trial 41 finished with value: 0.2155736890711538 and parameters: {'model_type': 'XGBoost', 'xgb_n_estimators': 550, 'xgb_learning_rate': 0.08118921873877057, 'xgb_max_depth': 4, 'xgb_subsample': 0.885304274842691, 'xgb_colsample_bytree': 0.8269314345850066, 'xgb_reg_alpha': 0.9113991820829632, 'xgb_reg_lambda': 0.9717474013649089}. Best is trial 36 with value: 0.2139852837704128.\n",
      "[I 2025-07-31 11:55:15,086] Trial 42 finished with value: 0.2162772549062327 and parameters: {'model_type': 'XGBoost', 'xgb_n_estimators': 600, 'xgb_learning_rate': 0.08270156570757538, 'xgb_max_depth': 4, 'xgb_subsample': 0.8743938677177097, 'xgb_colsample_bytree': 0.8318761762624453, 'xgb_reg_alpha': 0.9263589541713091, 'xgb_reg_lambda': 0.9884912476606097}. Best is trial 36 with value: 0.2139852837704128.\n",
      "[I 2025-07-31 11:55:23,086] Trial 43 finished with value: 0.2169825571325558 and parameters: {'model_type': 'XGBoost', 'xgb_n_estimators': 650, 'xgb_learning_rate': 0.08120294748687126, 'xgb_max_depth': 4, 'xgb_subsample': 0.8748702083049675, 'xgb_colsample_bytree': 0.8457801798327684, 'xgb_reg_alpha': 0.9042973172635713, 'xgb_reg_lambda': 0.9993694735253494}. Best is trial 36 with value: 0.2139852837704128.\n",
      "[I 2025-07-31 11:55:30,830] Trial 44 finished with value: 0.21647903975560676 and parameters: {'model_type': 'XGBoost', 'xgb_n_estimators': 650, 'xgb_learning_rate': 0.08395432104766548, 'xgb_max_depth': 4, 'xgb_subsample': 0.877656528049375, 'xgb_colsample_bytree': 0.8338548257249724, 'xgb_reg_alpha': 0.9228969015449017, 'xgb_reg_lambda': 0.9918726795303529}. Best is trial 36 with value: 0.2139852837704128.\n",
      "[I 2025-07-31 11:55:39,237] Trial 45 finished with value: 0.21082198233205526 and parameters: {'model_type': 'XGBoost', 'xgb_n_estimators': 700, 'xgb_learning_rate': 0.08007729251220097, 'xgb_max_depth': 4, 'xgb_subsample': 0.8728650516992217, 'xgb_colsample_bytree': 0.8308284354780312, 'xgb_reg_alpha': 0.909241559998174, 'xgb_reg_lambda': 0.9940950984119641}. Best is trial 45 with value: 0.21082198233205526.\n",
      "[I 2025-07-31 11:55:47,722] Trial 46 finished with value: 0.2147758879750102 and parameters: {'model_type': 'XGBoost', 'xgb_n_estimators': 700, 'xgb_learning_rate': 0.10226569028669845, 'xgb_max_depth': 5, 'xgb_subsample': 0.8706997706028363, 'xgb_colsample_bytree': 0.8187213690737096, 'xgb_reg_alpha': 0.914046360952234, 'xgb_reg_lambda': 0.9265560296474601}. Best is trial 45 with value: 0.21082198233205526.\n",
      "[I 2025-07-31 11:55:56,244] Trial 47 finished with value: 0.21307891977773075 and parameters: {'model_type': 'XGBoost', 'xgb_n_estimators': 700, 'xgb_learning_rate': 0.1038320585000718, 'xgb_max_depth': 5, 'xgb_subsample': 0.8650186556806311, 'xgb_colsample_bytree': 0.8204147196854398, 'xgb_reg_alpha': 0.8561167717331069, 'xgb_reg_lambda': 0.8838225214011652}. Best is trial 45 with value: 0.21082198233205526.\n",
      "[I 2025-07-31 11:56:04,918] Trial 48 finished with value: 0.21471458655206213 and parameters: {'model_type': 'XGBoost', 'xgb_n_estimators': 700, 'xgb_learning_rate': 0.10739243374831547, 'xgb_max_depth': 5, 'xgb_subsample': 0.8644307435000363, 'xgb_colsample_bytree': 0.8190701967929975, 'xgb_reg_alpha': 0.7318959680274473, 'xgb_reg_lambda': 0.9007836099127173}. Best is trial 45 with value: 0.21082198233205526.\n",
      "[I 2025-07-31 11:56:13,527] Trial 49 finished with value: 0.2127320255085642 and parameters: {'model_type': 'XGBoost', 'xgb_n_estimators': 700, 'xgb_learning_rate': 0.1064141360737597, 'xgb_max_depth': 5, 'xgb_subsample': 0.8308537111420251, 'xgb_colsample_bytree': 0.8611164432303843, 'xgb_reg_alpha': 0.7355279712940879, 'xgb_reg_lambda': 0.898411659937784}. Best is trial 45 with value: 0.21082198233205526.\n",
      "[I 2025-07-31 11:56:22,929] Trial 50 finished with value: 0.21423841689390946 and parameters: {'model_type': 'XGBoost', 'xgb_n_estimators': 750, 'xgb_learning_rate': 0.12375919905435057, 'xgb_max_depth': 6, 'xgb_subsample': 0.8179602183778627, 'xgb_colsample_bytree': 0.8669072557728041, 'xgb_reg_alpha': 0.614119876057549, 'xgb_reg_lambda': 0.891360337902614}. Best is trial 45 with value: 0.21082198233205526.\n",
      "[I 2025-07-31 11:56:33,449] Trial 51 finished with value: 0.2193801366196363 and parameters: {'model_type': 'XGBoost', 'xgb_n_estimators': 750, 'xgb_learning_rate': 0.12248731362390028, 'xgb_max_depth': 6, 'xgb_subsample': 0.8100583213821292, 'xgb_colsample_bytree': 0.8760352124325779, 'xgb_reg_alpha': 0.6244914225820245, 'xgb_reg_lambda': 0.9047785563363934}. Best is trial 45 with value: 0.21082198233205526.\n",
      "[I 2025-07-31 11:56:42,021] Trial 52 finished with value: 0.21154124673332095 and parameters: {'model_type': 'XGBoost', 'xgb_n_estimators': 700, 'xgb_learning_rate': 0.10756539287537886, 'xgb_max_depth': 5, 'xgb_subsample': 0.8328878993835264, 'xgb_colsample_bytree': 0.8604245859841411, 'xgb_reg_alpha': 0.7260623045064711, 'xgb_reg_lambda': 0.8727211300199706}. Best is trial 45 with value: 0.21082198233205526.\n",
      "[I 2025-07-31 11:56:51,256] Trial 53 finished with value: 0.22723718592708075 and parameters: {'model_type': 'XGBoost', 'xgb_n_estimators': 700, 'xgb_learning_rate': 0.12300734992278736, 'xgb_max_depth': 5, 'xgb_subsample': 0.8299398209455751, 'xgb_colsample_bytree': 0.8975399713872486, 'xgb_reg_alpha': 0.6019526023487326, 'xgb_reg_lambda': 0.7094750879960847}. Best is trial 45 with value: 0.21082198233205526.\n",
      "[I 2025-07-31 11:57:01,708] Trial 54 finished with value: 0.21641222935737295 and parameters: {'model_type': 'XGBoost', 'xgb_n_estimators': 750, 'xgb_learning_rate': 0.12935718347404407, 'xgb_max_depth': 6, 'xgb_subsample': 0.7857644293673582, 'xgb_colsample_bytree': 0.8567496734329753, 'xgb_reg_alpha': 0.4989055267180243, 'xgb_reg_lambda': 0.8454357433096426}. Best is trial 45 with value: 0.21082198233205526.\n",
      "[I 2025-07-31 11:57:13,597] Trial 55 finished with value: 0.24086043415728953 and parameters: {'model_type': 'XGBoost', 'xgb_n_estimators': 800, 'xgb_learning_rate': 0.143230458207144, 'xgb_max_depth': 5, 'xgb_subsample': 0.838864253584505, 'xgb_colsample_bytree': 0.8638639819006697, 'xgb_reg_alpha': 0.7547581155805894, 'xgb_reg_lambda': 0.24406985995166686}. Best is trial 45 with value: 0.21082198233205526.\n",
      "[I 2025-07-31 11:57:26,821] Trial 56 finished with value: 0.21353868201470275 and parameters: {'model_type': 'XGBoost', 'xgb_n_estimators': 700, 'xgb_learning_rate': 0.1031278428689269, 'xgb_max_depth': 6, 'xgb_subsample': 0.8073707795192784, 'xgb_colsample_bytree': 0.8822685593649818, 'xgb_reg_alpha': 0.6802587015674567, 'xgb_reg_lambda': 0.9164335979117808}. Best is trial 45 with value: 0.21082198233205526.\n",
      "[I 2025-07-31 11:57:27,057] Trial 57 finished with value: 0.3624303270453393 and parameters: {'model_type': 'SVR', 'svr_C': 4.077040436371904, 'svr_epsilon': 0.1776388678905421, 'svr_kernel': 'rbf'}. Best is trial 45 with value: 0.21082198233205526.\n",
      "[I 2025-07-31 11:57:40,391] Trial 58 finished with value: 0.22198324465994168 and parameters: {'model_type': 'XGBoost', 'xgb_n_estimators': 700, 'xgb_learning_rate': 0.10635330748352029, 'xgb_max_depth': 5, 'xgb_subsample': 0.7177802220999756, 'xgb_colsample_bytree': 0.8871687075592044, 'xgb_reg_alpha': 0.8532049931895379, 'xgb_reg_lambda': 0.9360306206601748}. Best is trial 45 with value: 0.21082198233205526.\n",
      "[I 2025-07-31 11:57:54,917] Trial 59 finished with value: 0.2224691278844569 and parameters: {'model_type': 'XGBoost', 'xgb_n_estimators': 650, 'xgb_learning_rate': 0.09350326302450317, 'xgb_max_depth': 7, 'xgb_subsample': 0.7714279517350117, 'xgb_colsample_bytree': 0.7866466355415679, 'xgb_reg_alpha': 0.6608419931841178, 'xgb_reg_lambda': 0.7430764457350176}. Best is trial 45 with value: 0.21082198233205526.\n",
      "[I 2025-07-31 11:58:04,188] Trial 60 finished with value: 0.2170850034212548 and parameters: {'model_type': 'XGBoost', 'xgb_n_estimators': 700, 'xgb_learning_rate': 0.11429572652523831, 'xgb_max_depth': 5, 'xgb_subsample': 0.8084119671344334, 'xgb_colsample_bytree': 0.8529400394539629, 'xgb_reg_alpha': 0.7318865640578006, 'xgb_reg_lambda': 0.8228121625634172}. Best is trial 45 with value: 0.21082198233205526.\n",
      "[I 2025-07-31 11:58:18,133] Trial 61 finished with value: 0.21433854764812169 and parameters: {'model_type': 'XGBoost', 'xgb_n_estimators': 750, 'xgb_learning_rate': 0.09169630641290102, 'xgb_max_depth': 6, 'xgb_subsample': 0.8220388872263836, 'xgb_colsample_bytree': 0.8748113590571445, 'xgb_reg_alpha': 0.5252003604228779, 'xgb_reg_lambda': 0.8953208021162682}. Best is trial 45 with value: 0.21082198233205526.\n",
      "[I 2025-07-31 11:58:30,797] Trial 62 finished with value: 0.21366652106283626 and parameters: {'model_type': 'XGBoost', 'xgb_n_estimators': 750, 'xgb_learning_rate': 0.10228110830531566, 'xgb_max_depth': 7, 'xgb_subsample': 0.8089535873314232, 'xgb_colsample_bytree': 0.8639381725557141, 'xgb_reg_alpha': 0.6414672003273322, 'xgb_reg_lambda': 0.9431388892163624}. Best is trial 45 with value: 0.21082198233205526.\n",
      "[I 2025-07-31 11:58:44,775] Trial 63 finished with value: 0.21374273557193443 and parameters: {'model_type': 'XGBoost', 'xgb_n_estimators': 800, 'xgb_learning_rate': 0.10339331874030211, 'xgb_max_depth': 8, 'xgb_subsample': 0.8056390622551467, 'xgb_colsample_bytree': 0.8850648691608893, 'xgb_reg_alpha': 0.8269810354298786, 'xgb_reg_lambda': 0.9441374101479494}. Best is trial 45 with value: 0.21082198233205526.\n",
      "[I 2025-07-31 11:59:00,739] Trial 64 finished with value: 0.21350695524045263 and parameters: {'model_type': 'XGBoost', 'xgb_n_estimators': 800, 'xgb_learning_rate': 0.10287668072425725, 'xgb_max_depth': 9, 'xgb_subsample': 0.8052617971196264, 'xgb_colsample_bytree': 0.8921290403254838, 'xgb_reg_alpha': 0.6644038892470288, 'xgb_reg_lambda': 0.9431568047455442}. Best is trial 45 with value: 0.21082198233205526.\n",
      "[I 2025-07-31 11:59:21,586] Trial 65 finished with value: 0.21811777447680333 and parameters: {'model_type': 'XGBoost', 'xgb_n_estimators': 750, 'xgb_learning_rate': 0.09946086345542107, 'xgb_max_depth': 10, 'xgb_subsample': 0.7748619100748552, 'xgb_colsample_bytree': 0.8988195813309334, 'xgb_reg_alpha': 0.6604250751945923, 'xgb_reg_lambda': 0.8418576569669938}. Best is trial 45 with value: 0.21082198233205526.\n",
      "[I 2025-07-31 11:59:37,249] Trial 66 finished with value: 0.2395532922710808 and parameters: {'model_type': 'XGBoost', 'xgb_n_estimators': 800, 'xgb_learning_rate': 0.11104993065216832, 'xgb_max_depth': 8, 'xgb_subsample': 0.8282495597164112, 'xgb_colsample_bytree': 0.8834121781344859, 'xgb_reg_alpha': 0.5661010405142352, 'xgb_reg_lambda': 0.03636221041551124}. Best is trial 45 with value: 0.21082198233205526.\n",
      "[I 2025-07-31 11:59:50,186] Trial 67 finished with value: 0.22396475983889474 and parameters: {'model_type': 'XGBoost', 'xgb_n_estimators': 700, 'xgb_learning_rate': 0.11736924799830169, 'xgb_max_depth': 7, 'xgb_subsample': 0.7995206868447913, 'xgb_colsample_bytree': 0.8569621451228473, 'xgb_reg_alpha': 0.4693799613660853, 'xgb_reg_lambda': 0.9535742426787114}. Best is trial 45 with value: 0.21082198233205526.\n",
      "[I 2025-07-31 12:00:06,363] Trial 68 finished with value: 0.21797934611321515 and parameters: {'model_type': 'XGBoost', 'xgb_n_estimators': 750, 'xgb_learning_rate': 0.09126436706610408, 'xgb_max_depth': 9, 'xgb_subsample': 0.8161394827225673, 'xgb_colsample_bytree': 0.8715148802237733, 'xgb_reg_alpha': 0.7560673148082079, 'xgb_reg_lambda': 0.7850893950065734}. Best is trial 45 with value: 0.21082198233205526.\n",
      "[I 2025-07-31 12:00:06,649] Trial 69 finished with value: 0.31042123588505616 and parameters: {'model_type': 'SVR', 'svr_C': 7.748038882092953, 'svr_epsilon': 0.12038699221521114, 'svr_kernel': 'rbf'}. Best is trial 45 with value: 0.21082198233205526.\n",
      "[I 2025-07-31 12:00:22,152] Trial 70 finished with value: 0.22125908384001317 and parameters: {'model_type': 'XGBoost', 'xgb_n_estimators': 650, 'xgb_learning_rate': 0.10376992260117456, 'xgb_max_depth': 7, 'xgb_subsample': 0.7868076841086619, 'xgb_colsample_bytree': 0.8883733536964891, 'xgb_reg_alpha': 0.07147647569213444, 'xgb_reg_lambda': 0.9248908609078242}. Best is trial 45 with value: 0.21082198233205526.\n",
      "[I 2025-07-31 12:00:35,521] Trial 71 finished with value: 0.2150959792371274 and parameters: {'model_type': 'XGBoost', 'xgb_n_estimators': 800, 'xgb_learning_rate': 0.10382667528931185, 'xgb_max_depth': 8, 'xgb_subsample': 0.8047915959329148, 'xgb_colsample_bytree': 0.8819570969974436, 'xgb_reg_alpha': 0.7101424934391555, 'xgb_reg_lambda': 0.9469548688952424}. Best is trial 45 with value: 0.21082198233205526.\n",
      "[I 2025-07-31 12:00:51,267] Trial 72 finished with value: 0.21294701206014346 and parameters: {'model_type': 'XGBoost', 'xgb_n_estimators': 800, 'xgb_learning_rate': 0.0963482109542541, 'xgb_max_depth': 9, 'xgb_subsample': 0.8547707804304641, 'xgb_colsample_bytree': 0.8917983937086509, 'xgb_reg_alpha': 0.8027586178857613, 'xgb_reg_lambda': 0.9458822485972438}. Best is trial 45 with value: 0.21082198233205526.\n",
      "[I 2025-07-31 12:01:06,361] Trial 73 finished with value: 0.21674424189690256 and parameters: {'model_type': 'XGBoost', 'xgb_n_estimators': 800, 'xgb_learning_rate': 0.09606176597757347, 'xgb_max_depth': 9, 'xgb_subsample': 0.8581742423486993, 'xgb_colsample_bytree': 0.8105144941740505, 'xgb_reg_alpha': 0.7820711594465941, 'xgb_reg_lambda': 0.8560425128873792}. Best is trial 45 with value: 0.21082198233205526.\n",
      "[I 2025-07-31 12:01:21,786] Trial 74 finished with value: 0.21824353306008115 and parameters: {'model_type': 'XGBoost', 'xgb_n_estimators': 700, 'xgb_learning_rate': 0.11117463691139227, 'xgb_max_depth': 9, 'xgb_subsample': 0.8514114973722865, 'xgb_colsample_bytree': 0.8925528575480081, 'xgb_reg_alpha': 0.6858671919153726, 'xgb_reg_lambda': 0.8879939135303273}. Best is trial 45 with value: 0.21082198233205526.\n",
      "[I 2025-07-31 12:01:32,401] Trial 75 finished with value: 0.22483418182940076 and parameters: {'model_type': 'XGBoost', 'xgb_n_estimators': 750, 'xgb_learning_rate': 0.11771057759776417, 'xgb_max_depth': 9, 'xgb_subsample': 0.8398657838860863, 'xgb_colsample_bytree': 0.8634724319386529, 'xgb_reg_alpha': 0.8300734813473837, 'xgb_reg_lambda': 0.49564239304652197}. Best is trial 45 with value: 0.21082198233205526.\n",
      "[I 2025-07-31 12:01:43,555] Trial 76 finished with value: 0.2130577389407157 and parameters: {'model_type': 'XGBoost', 'xgb_n_estimators': 750, 'xgb_learning_rate': 0.0880697123999242, 'xgb_max_depth': 6, 'xgb_subsample': 0.8251601848985466, 'xgb_colsample_bytree': 0.8506435410680877, 'xgb_reg_alpha': 0.7634380267061157, 'xgb_reg_lambda': 0.8126317394827245}. Best is trial 45 with value: 0.21082198233205526.\n",
      "[I 2025-07-31 12:02:07,009] Trial 77 finished with value: 0.2766665432407003 and parameters: {'model_type': 'RandomForest', 'rf_n_estimators': 400, 'rf_max_depth': 8, 'rf_min_samples_split': 10, 'rf_min_samples_leaf': 4, 'rf_max_features': 0.7019427470406746}. Best is trial 45 with value: 0.21082198233205526.\n",
      "[I 2025-07-31 12:02:19,156] Trial 78 finished with value: 0.23350103009989245 and parameters: {'model_type': 'XGBoost', 'xgb_n_estimators': 700, 'xgb_learning_rate': 0.08920666994895979, 'xgb_max_depth': 6, 'xgb_subsample': 0.833005553775781, 'xgb_colsample_bytree': 0.8502156964310494, 'xgb_reg_alpha': 0.18556974973038554, 'xgb_reg_lambda': 0.7470820209058149}. Best is trial 45 with value: 0.21082198233205526.\n",
      "[I 2025-07-31 12:02:34,395] Trial 79 finished with value: 0.21402955714371466 and parameters: {'model_type': 'XGBoost', 'xgb_n_estimators': 800, 'xgb_learning_rate': 0.08658319430290079, 'xgb_max_depth': 6, 'xgb_subsample': 0.8478292834402935, 'xgb_colsample_bytree': 0.8783679028990357, 'xgb_reg_alpha': 0.7656792632114096, 'xgb_reg_lambda': 0.8163499540864222}. Best is trial 45 with value: 0.21082198233205526.\n",
      "[I 2025-07-31 12:02:47,490] Trial 80 finished with value: 0.21498516577642715 and parameters: {'model_type': 'XGBoost', 'xgb_n_estimators': 650, 'xgb_learning_rate': 0.095826182814906, 'xgb_max_depth': 10, 'xgb_subsample': 0.8236792214003132, 'xgb_colsample_bytree': 0.8412089247270782, 'xgb_reg_alpha': 0.840024810188468, 'xgb_reg_lambda': 0.8649928439326586}. Best is trial 45 with value: 0.21082198233205526.\n",
      "[I 2025-07-31 12:02:59,167] Trial 81 finished with value: 0.21322339573301127 and parameters: {'model_type': 'XGBoost', 'xgb_n_estimators': 750, 'xgb_learning_rate': 0.10014744179936695, 'xgb_max_depth': 7, 'xgb_subsample': 0.8149658720511709, 'xgb_colsample_bytree': 0.8624298372840958, 'xgb_reg_alpha': 0.6383710122032512, 'xgb_reg_lambda': 0.9524601553609888}. Best is trial 45 with value: 0.21082198233205526.\n",
      "[I 2025-07-31 12:03:10,535] Trial 82 finished with value: 0.21279452516563388 and parameters: {'model_type': 'XGBoost', 'xgb_n_estimators': 750, 'xgb_learning_rate': 0.09942553407795376, 'xgb_max_depth': 5, 'xgb_subsample': 0.8368591446421213, 'xgb_colsample_bytree': 0.8467748642761478, 'xgb_reg_alpha': 0.7143201456262058, 'xgb_reg_lambda': 0.9134552583826838}. Best is trial 45 with value: 0.21082198233205526.\n",
      "[I 2025-07-31 12:03:21,292] Trial 83 finished with value: 0.21369479401576585 and parameters: {'model_type': 'XGBoost', 'xgb_n_estimators': 750, 'xgb_learning_rate': 0.09854788781833368, 'xgb_max_depth': 5, 'xgb_subsample': 0.8404657506784753, 'xgb_colsample_bytree': 0.849425753387677, 'xgb_reg_alpha': 0.7261147291745836, 'xgb_reg_lambda': 0.9560577679685123}. Best is trial 45 with value: 0.21082198233205526.\n",
      "[I 2025-07-31 12:03:30,395] Trial 84 finished with value: 0.21022925732404865 and parameters: {'model_type': 'XGBoost', 'xgb_n_estimators': 800, 'xgb_learning_rate': 0.1082808901781176, 'xgb_max_depth': 5, 'xgb_subsample': 0.8648947221392195, 'xgb_colsample_bytree': 0.8351822599281734, 'xgb_reg_alpha': 0.9542741348390809, 'xgb_reg_lambda': 0.8824242087282689}. Best is trial 84 with value: 0.21022925732404865.\n",
      "[I 2025-07-31 12:03:40,234] Trial 85 finished with value: 0.21555540833261136 and parameters: {'model_type': 'XGBoost', 'xgb_n_estimators': 750, 'xgb_learning_rate': 0.07355520014407911, 'xgb_max_depth': 5, 'xgb_subsample': 0.8644268657653871, 'xgb_colsample_bytree': 0.8096793007487576, 'xgb_reg_alpha': 0.950437191618011, 'xgb_reg_lambda': 0.7871444245052773}. Best is trial 84 with value: 0.21022925732404865.\n",
      "[I 2025-07-31 12:03:50,918] Trial 86 finished with value: 0.21447395299889985 and parameters: {'model_type': 'XGBoost', 'xgb_n_estimators': 800, 'xgb_learning_rate': 0.10860127789009305, 'xgb_max_depth': 5, 'xgb_subsample': 0.8581301028189827, 'xgb_colsample_bytree': 0.8339686921536533, 'xgb_reg_alpha': 0.8016622946641668, 'xgb_reg_lambda': 0.8765707963255597}. Best is trial 84 with value: 0.21022925732404865.\n",
      "[I 2025-07-31 12:03:51,026] Trial 87 finished with value: 0.7058144447039427 and parameters: {'model_type': 'SVR', 'svr_C': 3.2605319393953267, 'svr_epsilon': 0.24456432095314165, 'svr_kernel': 'poly', 'svr_degree': 3}. Best is trial 84 with value: 0.21022925732404865.\n",
      "[I 2025-07-31 12:04:05,550] Trial 88 finished with value: 0.21606313834868374 and parameters: {'model_type': 'XGBoost', 'xgb_n_estimators': 750, 'xgb_learning_rate': 0.0861510179270534, 'xgb_max_depth': 5, 'xgb_subsample': 0.891868936643828, 'xgb_colsample_bytree': 0.844684484861665, 'xgb_reg_alpha': 0.8701333262327803, 'xgb_reg_lambda': 0.8091841851589145}. Best is trial 84 with value: 0.21022925732404865.\n",
      "[I 2025-07-31 12:04:44,596] Trial 89 finished with value: 0.26595210858938806 and parameters: {'model_type': 'RandomForest', 'rf_n_estimators': 600, 'rf_max_depth': 10, 'rf_min_samples_split': 8, 'rf_min_samples_leaf': 4, 'rf_max_features': 0.8333225981464704}. Best is trial 84 with value: 0.21022925732404865.\n",
      "[I 2025-07-31 12:04:53,399] Trial 90 finished with value: 0.21086237007248868 and parameters: {'model_type': 'XGBoost', 'xgb_n_estimators': 700, 'xgb_learning_rate': 0.1138971322343825, 'xgb_max_depth': 5, 'xgb_subsample': 0.8539375577313245, 'xgb_colsample_bytree': 0.8314892680395564, 'xgb_reg_alpha': 0.9651736796170187, 'xgb_reg_lambda': 0.9045323537528829}. Best is trial 84 with value: 0.21022925732404865.\n",
      "[I 2025-07-31 12:05:02,896] Trial 91 finished with value: 0.21692723810295367 and parameters: {'model_type': 'XGBoost', 'xgb_n_estimators': 700, 'xgb_learning_rate': 0.07702194681274113, 'xgb_max_depth': 5, 'xgb_subsample': 0.8674209042759152, 'xgb_colsample_bytree': 0.8296464098892999, 'xgb_reg_alpha': 0.9721318213914115, 'xgb_reg_lambda': 0.9034440477866095}. Best is trial 84 with value: 0.21022925732404865.\n",
      "[I 2025-07-31 12:05:11,096] Trial 92 finished with value: 0.21465234806236552 and parameters: {'model_type': 'XGBoost', 'xgb_n_estimators': 700, 'xgb_learning_rate': 0.11490912601346201, 'xgb_max_depth': 5, 'xgb_subsample': 0.8540134028165847, 'xgb_colsample_bytree': 0.8577096585998009, 'xgb_reg_alpha': 0.9471442444785703, 'xgb_reg_lambda': 0.9775348777862205}. Best is trial 84 with value: 0.21022925732404865.\n",
      "[I 2025-07-31 12:05:20,190] Trial 93 finished with value: 0.20894060050915186 and parameters: {'model_type': 'XGBoost', 'xgb_n_estimators': 750, 'xgb_learning_rate': 0.11039661805272287, 'xgb_max_depth': 5, 'xgb_subsample': 0.8467863851316673, 'xgb_colsample_bytree': 0.8348985964527575, 'xgb_reg_alpha': 0.8910671816838251, 'xgb_reg_lambda': 0.8461534612165245}. Best is trial 93 with value: 0.20894060050915186.\n",
      "[I 2025-07-31 12:05:28,511] Trial 94 finished with value: 0.21206127904420594 and parameters: {'model_type': 'XGBoost', 'xgb_n_estimators': 650, 'xgb_learning_rate': 0.10897287820944354, 'xgb_max_depth': 5, 'xgb_subsample': 0.8465441431365376, 'xgb_colsample_bytree': 0.8370805236668262, 'xgb_reg_alpha': 0.9679602497497153, 'xgb_reg_lambda': 0.8270278979024642}. Best is trial 93 with value: 0.20894060050915186.\n",
      "[I 2025-07-31 12:05:35,575] Trial 95 finished with value: 0.22288358929230326 and parameters: {'model_type': 'XGBoost', 'xgb_n_estimators': 600, 'xgb_learning_rate': 0.11198210848679613, 'xgb_max_depth': 4, 'xgb_subsample': 0.8483014588673132, 'xgb_colsample_bytree': 0.8365261968066898, 'xgb_reg_alpha': 0.9701157712261216, 'xgb_reg_lambda': 0.7495046371443049}. Best is trial 93 with value: 0.20894060050915186.\n",
      "[I 2025-07-31 12:05:44,425] Trial 96 finished with value: 0.20852052293949122 and parameters: {'model_type': 'XGBoost', 'xgb_n_estimators': 650, 'xgb_learning_rate': 0.12115835832645282, 'xgb_max_depth': 5, 'xgb_subsample': 0.8362721722240525, 'xgb_colsample_bytree': 0.8440517050412732, 'xgb_reg_alpha': 0.9987313524203768, 'xgb_reg_lambda': 0.8401018015463615}. Best is trial 96 with value: 0.20852052293949122.\n",
      "[I 2025-07-31 12:05:53,446] Trial 97 finished with value: 0.21449268517699704 and parameters: {'model_type': 'XGBoost', 'xgb_n_estimators': 650, 'xgb_learning_rate': 0.12625101663495916, 'xgb_max_depth': 5, 'xgb_subsample': 0.8365224842747224, 'xgb_colsample_bytree': 0.8272537752165129, 'xgb_reg_alpha': 0.9970634867004393, 'xgb_reg_lambda': 0.8439454536324995}. Best is trial 96 with value: 0.20852052293949122.\n",
      "[I 2025-07-31 12:06:02,216] Trial 98 finished with value: 0.2099837986341586 and parameters: {'model_type': 'XGBoost', 'xgb_n_estimators': 650, 'xgb_learning_rate': 0.11958367018634114, 'xgb_max_depth': 4, 'xgb_subsample': 0.844177232420391, 'xgb_colsample_bytree': 0.8421843682232448, 'xgb_reg_alpha': 0.9589677225661954, 'xgb_reg_lambda': 0.9122498541597003}. Best is trial 96 with value: 0.20852052293949122.\n",
      "[I 2025-07-31 12:06:12,593] Trial 99 finished with value: 0.23018737937513442 and parameters: {'model_type': 'XGBoost', 'xgb_n_estimators': 600, 'xgb_learning_rate': 0.11735211319671518, 'xgb_max_depth': 4, 'xgb_subsample': 0.844270178023273, 'xgb_colsample_bytree': 0.8434745873230718, 'xgb_reg_alpha': 0.8919439433813529, 'xgb_reg_lambda': 0.6800351128943859}. Best is trial 96 with value: 0.20852052293949122.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Otimização concluída!\n",
      "Melhor MSE: 0.20852\n",
      "Baseline MSE: 0.22349\n",
      "Melhoria: 6.70%\n",
      "Melhores parâmetros: {'model_type': 'XGBoost', 'xgb_n_estimators': 650, 'xgb_learning_rate': 0.12115835832645282, 'xgb_max_depth': 5, 'xgb_subsample': 0.8362721722240525, 'xgb_colsample_bytree': 0.8440517050412732, 'xgb_reg_alpha': 0.9987313524203768, 'xgb_reg_lambda': 0.8401018015463615}\n"
     ]
    }
   ],
   "source": [
    "# Otimização mais conservadora\n",
    "n_trials = 100  # Reduzido para evitar overfitting\n",
    "study.optimize(conservative_objective, n_trials=n_trials, timeout=7200)  \n",
    "\n",
    "print(\"Otimização concluída!\")\n",
    "print(f\"Melhor MSE: {study.best_value:.5f}\")\n",
    "print(f\"Baseline MSE: {best_baseline_score:.5f}\")\n",
    "print(f\"Melhoria: {((best_baseline_score - study.best_value) / best_baseline_score * 100):.2f}%\")\n",
    "print(f\"Melhores parâmetros: {study.best_params}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d46bc69-3d25-48ab-a9db-448cb7f428a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Modelo otimizado XGBoost adicionado ao ensemble\n"
     ]
    }
   ],
   "source": [
    "# ==================== CRIAR ENSEMBLE HÍBRIDO ====================\n",
    "\n",
    "def get_hybrid_models(study, baseline_models):\n",
    "    \"\"\"Combina modelo otimizado com baselines comprovados\"\"\"\n",
    "    models = {}\n",
    "    \n",
    "    # Adicionar baseline sempre (segurança)\n",
    "    models.update(baseline_models)\n",
    "    \n",
    "    # Só adicionar modelo otimizado se for melhor que baseline\n",
    "    if study.best_value < best_baseline_score * 1.1:  # Até 10% pior é aceitável\n",
    "        best_params = study.best_params\n",
    "        model_type = best_params['model_type']\n",
    "        \n",
    "        if model_type == 'RandomForest':\n",
    "            rf_params = {k.replace('rf_', ''): v for k, v in best_params.items() if k.startswith('rf_')}\n",
    "            rf_params['random_state'] = 42\n",
    "            rf_params['n_jobs'] = -1\n",
    "            models['RandomForest_Optimized'] = MultiOutputRegressor(RandomForestRegressor(**rf_params))\n",
    "        \n",
    "        elif model_type == 'XGBoost':\n",
    "            xgb_params = {k.replace('xgb_', ''): v for k, v in best_params.items() if k.startswith('xgb_')}\n",
    "            xgb_params['random_state'] = 42\n",
    "            xgb_params['n_jobs'] = -1\n",
    "            models['XGBoost_Optimized'] = MultiOutputRegressor(XGBRegressor(**xgb_params))\n",
    "        \n",
    "        elif model_type == 'SVR':\n",
    "            svr_params = {}\n",
    "            for k, v in best_params.items():\n",
    "                if k.startswith('svr_'):\n",
    "                    param_name = k.replace('svr_', '')\n",
    "                    svr_params[param_name] = v\n",
    "            models['SVR_Optimized'] = MultiOutputRegressor(SVR(**svr_params))\n",
    "        \n",
    "        print(f\"✅ Modelo otimizado {model_type} adicionado ao ensemble\")\n",
    "    else:\n",
    "        print(\"⚠️  Modelo otimizado não foi melhor que baseline - usando apenas baselines\")\n",
    "    \n",
    "    return models\n",
    "\n",
    "# Obter modelos híbridos\n",
    "hybrid_models = get_hybrid_models(study, baseline_models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f263c81-3d95-43b1-95ef-f69d23d8593e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Treinando ensemble final com 4 modelos...\n",
      "\n",
      "Treinando RandomForest...\n",
      "  Fold 1/50\n",
      "  Fold MSE: 0.00338\n",
      "  Fold 2/50\n",
      "  Fold MSE: 0.00420\n",
      "  Fold 3/50\n",
      "  Fold MSE: 0.02920\n",
      "  Fold 4/50\n",
      "  Fold MSE: 0.06636\n",
      "  Fold 5/50\n",
      "  Fold MSE: 0.07890\n",
      "  Fold 6/50\n",
      "  Fold MSE: 0.00855\n",
      "  Fold 7/50\n",
      "  Fold MSE: 0.00368\n",
      "  Fold 8/50\n",
      "  Fold MSE: 0.00955\n",
      "  Fold 9/50\n",
      "  Fold MSE: 0.00035\n",
      "  Fold 10/50\n",
      "  Fold MSE: 0.00043\n",
      "  Fold 11/50\n",
      "  Fold MSE: 0.00001\n",
      "  Fold 12/50\n",
      "  Fold MSE: 0.00689\n",
      "  Fold 13/50\n",
      "  Fold MSE: 0.01107\n",
      "  Fold 14/50\n",
      "  Fold MSE: 0.00678\n",
      "  Fold 15/50\n",
      "  Fold MSE: 0.59527\n",
      "  Fold 16/50\n",
      "  Fold MSE: 2.35203\n",
      "  Fold 17/50\n",
      "  Fold MSE: 0.00154\n",
      "  Fold 18/50\n",
      "  Fold MSE: 0.00367\n",
      "  Fold 19/50\n",
      "  Fold MSE: 0.00106\n",
      "  Fold 20/50\n",
      "  Fold MSE: 0.06180\n",
      "  Fold 21/50\n",
      "  Fold MSE: 0.07586\n",
      "  Fold 22/50\n",
      "  Fold MSE: 0.00564\n",
      "  Fold 23/50\n",
      "  Fold MSE: 0.59416\n",
      "  Fold 24/50\n",
      "  Fold MSE: 0.02071\n",
      "  Fold 25/50\n",
      "  Fold MSE: 0.09790\n",
      "  Fold 26/50\n",
      "  Fold MSE: 0.00477\n",
      "  Fold 27/50\n",
      "  Fold MSE: 0.07993\n",
      "  Fold 28/50\n",
      "  Fold MSE: 0.00005\n",
      "  Fold 29/50\n",
      "  Fold MSE: 0.07574\n",
      "  Fold 30/50\n",
      "  Fold MSE: 0.24058\n",
      "  Fold 31/50\n",
      "  Fold MSE: 0.00470\n",
      "  Fold 32/50\n",
      "  Fold MSE: 0.00553\n",
      "  Fold 33/50\n",
      "  Fold MSE: 0.00867\n",
      "  Fold 34/50\n",
      "  Fold MSE: 0.07833\n",
      "  Fold 35/50\n",
      "  Fold MSE: 0.00255\n",
      "  Fold 36/50\n",
      "  Fold MSE: 0.00158\n",
      "  Fold 37/50\n",
      "  Fold MSE: 3.90880\n",
      "  Fold 38/50\n",
      "  Fold MSE: 0.00032\n",
      "  Fold 39/50\n",
      "  Fold MSE: 0.35792\n",
      "  Fold 40/50\n",
      "  Fold MSE: 0.03805\n",
      "  Fold 41/50\n",
      "  Fold MSE: 0.48551\n",
      "  Fold 42/50\n",
      "  Fold MSE: 0.61260\n",
      "  Fold 43/50\n",
      "  Fold MSE: 0.00090\n",
      "  Fold 44/50\n",
      "  Fold MSE: 0.00946\n",
      "  Fold 45/50\n",
      "  Fold MSE: 0.02100\n",
      "  Fold 46/50\n",
      "  Fold MSE: 0.02503\n",
      "  Fold 47/50\n",
      "  Fold MSE: 0.60902\n",
      "  Fold 48/50\n",
      "  Fold MSE: 0.00210\n",
      "  Fold 49/50\n",
      "  Fold MSE: 0.01539\n",
      "  Fold 50/50\n",
      "  Fold MSE: 0.01813\n",
      "RandomForest OOF MSE: 0.21080\n",
      "\n",
      "Treinando XGBoost...\n",
      "  Fold 1/50\n",
      "  Fold MSE: 0.00958\n",
      "  Fold 2/50\n",
      "  Fold MSE: 0.00861\n",
      "  Fold 3/50\n",
      "  Fold MSE: 0.03420\n",
      "  Fold 4/50\n",
      "  Fold MSE: 0.00044\n",
      "  Fold 5/50\n",
      "  Fold MSE: 0.03491\n",
      "  Fold 6/50\n",
      "  Fold MSE: 0.00472\n",
      "  Fold 7/50\n",
      "  Fold MSE: 0.00279\n",
      "  Fold 8/50\n",
      "  Fold MSE: 0.01222\n",
      "  Fold 9/50\n",
      "  Fold MSE: 0.00056\n",
      "  Fold 10/50\n",
      "  Fold MSE: 0.00115\n",
      "  Fold 11/50\n",
      "  Fold MSE: 0.00001\n",
      "  Fold 12/50\n",
      "  Fold MSE: 0.00300\n",
      "  Fold 13/50\n",
      "  Fold MSE: 0.00199\n",
      "  Fold 14/50\n",
      "  Fold MSE: 0.01006\n",
      "  Fold 15/50\n",
      "  Fold MSE: 0.80781\n",
      "  Fold 16/50\n",
      "  Fold MSE: 2.33143\n",
      "  Fold 17/50\n",
      "  Fold MSE: 0.00596\n",
      "  Fold 18/50\n",
      "  Fold MSE: 0.00517\n",
      "  Fold 19/50\n",
      "  Fold MSE: 0.00251\n",
      "  Fold 20/50\n",
      "  Fold MSE: 0.07438\n",
      "  Fold 21/50\n",
      "  Fold MSE: 0.20549\n",
      "  Fold 22/50\n",
      "  Fold MSE: 0.00740\n",
      "  Fold 23/50\n",
      "  Fold MSE: 0.83167\n",
      "  Fold 24/50\n",
      "  Fold MSE: 0.01776\n",
      "  Fold 25/50\n",
      "  Fold MSE: 0.07783\n",
      "  Fold 26/50\n",
      "  Fold MSE: 0.00648\n",
      "  Fold 27/50\n",
      "  Fold MSE: 0.02720\n",
      "  Fold 28/50\n",
      "  Fold MSE: 0.00011\n",
      "  Fold 29/50\n",
      "  Fold MSE: 0.03543\n",
      "  Fold 30/50\n",
      "  Fold MSE: 0.08395\n",
      "  Fold 31/50\n",
      "  Fold MSE: 0.00887\n",
      "  Fold 32/50\n",
      "  Fold MSE: 0.01047\n",
      "  Fold 33/50\n",
      "  Fold MSE: 0.00074\n",
      "  Fold 34/50\n",
      "  Fold MSE: 0.03169\n",
      "  Fold 35/50\n",
      "  Fold MSE: 0.00398\n",
      "  Fold 36/50\n",
      "  Fold MSE: 0.00072\n",
      "  Fold 37/50\n",
      "  Fold MSE: 3.91139\n",
      "  Fold 38/50\n",
      "  Fold MSE: 0.00105\n",
      "  Fold 39/50\n",
      "  Fold MSE: 0.29884\n",
      "  Fold 40/50\n",
      "  Fold MSE: 0.02260\n",
      "  Fold 41/50\n",
      "  Fold MSE: 0.27394\n",
      "  Fold 42/50\n",
      "  Fold MSE: 1.30344\n",
      "  Fold 43/50\n",
      "  Fold MSE: 0.00036\n",
      "  Fold 44/50\n",
      "  Fold MSE: 0.00984\n",
      "  Fold 45/50\n",
      "  Fold MSE: 0.01970\n",
      "  Fold 46/50\n",
      "  Fold MSE: 0.01589\n",
      "  Fold 47/50\n",
      "  Fold MSE: 0.28158\n",
      "  Fold 48/50\n",
      "  Fold MSE: 0.01614\n",
      "  Fold 49/50\n",
      "  Fold MSE: 0.01121\n",
      "  Fold 50/50\n",
      "  Fold MSE: 0.00527\n",
      "XGBoost OOF MSE: 0.21515\n",
      "\n",
      "Treinando SVR...\n",
      "  Fold 1/50\n",
      "  Fold MSE: 0.00880\n",
      "  Fold 2/50\n",
      "  Fold MSE: 0.05310\n",
      "  Fold 3/50\n",
      "  Fold MSE: 0.57392\n",
      "  Fold 4/50\n",
      "  Fold MSE: 0.31616\n",
      "  Fold 5/50\n",
      "  Fold MSE: 0.18911\n",
      "  Fold 6/50\n",
      "  Fold MSE: 0.01492\n",
      "  Fold 7/50\n",
      "  Fold MSE: 0.00694\n",
      "  Fold 8/50\n",
      "  Fold MSE: 0.00965\n",
      "  Fold 9/50\n",
      "  Fold MSE: 0.00601\n",
      "  Fold 10/50\n",
      "  Fold MSE: 0.00672\n",
      "  Fold 11/50\n",
      "  Fold MSE: 0.00362\n",
      "  Fold 12/50\n",
      "  Fold MSE: 0.06220\n",
      "  Fold 13/50\n",
      "  Fold MSE: 0.02792\n",
      "  Fold 14/50\n",
      "  Fold MSE: 0.01372\n",
      "  Fold 15/50\n",
      "  Fold MSE: 0.45077\n",
      "  Fold 16/50\n",
      "  Fold MSE: 3.08058\n",
      "  Fold 17/50\n",
      "  Fold MSE: 0.03517\n",
      "  Fold 18/50\n",
      "  Fold MSE: 0.00851\n",
      "  Fold 19/50\n",
      "  Fold MSE: 0.01447\n",
      "  Fold 20/50\n",
      "  Fold MSE: 0.16793\n",
      "  Fold 21/50\n",
      "  Fold MSE: 0.47199\n",
      "  Fold 22/50\n",
      "  Fold MSE: 0.01422\n",
      "  Fold 23/50\n",
      "  Fold MSE: 0.65752\n",
      "  Fold 24/50\n",
      "  Fold MSE: 0.03800\n",
      "  Fold 25/50\n",
      "  Fold MSE: 0.20377\n",
      "  Fold 26/50\n",
      "  Fold MSE: 0.01374\n",
      "  Fold 27/50\n",
      "  Fold MSE: 0.17782\n",
      "  Fold 28/50\n",
      "  Fold MSE: 0.00355\n",
      "  Fold 29/50\n",
      "  Fold MSE: 0.10945\n",
      "  Fold 30/50\n",
      "  Fold MSE: 0.59384\n",
      "  Fold 31/50\n",
      "  Fold MSE: 0.01616\n",
      "  Fold 32/50\n",
      "  Fold MSE: 0.02858\n",
      "  Fold 33/50\n",
      "  Fold MSE: 0.01833\n",
      "  Fold 34/50\n",
      "  Fold MSE: 0.10087\n",
      "  Fold 35/50\n",
      "  Fold MSE: 0.00767\n",
      "  Fold 36/50\n",
      "  Fold MSE: 0.00513\n",
      "  Fold 37/50\n",
      "  Fold MSE: 5.78200\n",
      "  Fold 38/50\n",
      "  Fold MSE: 0.00505\n",
      "  Fold 39/50\n",
      "  Fold MSE: 0.58633\n",
      "  Fold 40/50\n",
      "  Fold MSE: 0.11179\n",
      "  Fold 41/50\n",
      "  Fold MSE: 1.09019\n",
      "  Fold 42/50\n",
      "  Fold MSE: 0.07457\n",
      "  Fold 43/50\n",
      "  Fold MSE: 0.00901\n",
      "  Fold 44/50\n",
      "  Fold MSE: 0.06685\n",
      "  Fold 45/50\n",
      "  Fold MSE: 0.05351\n",
      "  Fold 46/50\n",
      "  Fold MSE: 0.17947\n",
      "  Fold 47/50\n",
      "  Fold MSE: 1.72484\n",
      "  Fold 48/50\n",
      "  Fold MSE: 0.11541\n",
      "  Fold 49/50\n",
      "  Fold MSE: 0.01269\n",
      "  Fold 50/50\n",
      "  Fold MSE: 0.02998\n",
      "SVR OOF MSE: 0.34479\n",
      "\n",
      "Treinando XGBoost_Optimized...\n",
      "  Fold 1/50\n",
      "  Fold MSE: 0.02909\n",
      "  Fold 2/50\n",
      "  Fold MSE: 0.00509\n",
      "  Fold 3/50\n",
      "  Fold MSE: 0.01494\n",
      "  Fold 4/50\n",
      "  Fold MSE: 0.00186\n",
      "  Fold 5/50\n",
      "  Fold MSE: 0.03965\n",
      "  Fold 6/50\n",
      "  Fold MSE: 0.00333\n",
      "  Fold 7/50\n",
      "  Fold MSE: 0.00250\n",
      "  Fold 8/50\n",
      "  Fold MSE: 0.01158\n",
      "  Fold 9/50\n",
      "  Fold MSE: 0.00096\n",
      "  Fold 10/50\n",
      "  Fold MSE: 0.00076\n",
      "  Fold 11/50\n",
      "  Fold MSE: 0.00006\n",
      "  Fold 12/50\n",
      "  Fold MSE: 0.00394\n",
      "  Fold 13/50\n",
      "  Fold MSE: 0.00228\n",
      "  Fold 14/50\n",
      "  Fold MSE: 0.00927\n",
      "  Fold 15/50\n",
      "  Fold MSE: 0.78222\n",
      "  Fold 16/50\n",
      "  Fold MSE: 2.58393\n",
      "  Fold 17/50\n",
      "  Fold MSE: 0.00772\n",
      "  Fold 18/50\n",
      "  Fold MSE: 0.01223\n",
      "  Fold 19/50\n",
      "  Fold MSE: 0.00103\n",
      "  Fold 20/50\n",
      "  Fold MSE: 0.06109\n",
      "  Fold 21/50\n",
      "  Fold MSE: 0.17142\n",
      "  Fold 22/50\n",
      "  Fold MSE: 0.00433\n",
      "  Fold 23/50\n",
      "  Fold MSE: 0.71026\n",
      "  Fold 24/50\n",
      "  Fold MSE: 0.01320\n",
      "  Fold 25/50\n",
      "  Fold MSE: 0.06581\n",
      "  Fold 26/50\n",
      "  Fold MSE: 0.00923\n",
      "  Fold 27/50\n",
      "  Fold MSE: 0.01991\n",
      "  Fold 28/50\n",
      "  Fold MSE: 0.00012\n",
      "  Fold 29/50\n",
      "  Fold MSE: 0.03186\n",
      "  Fold 30/50\n",
      "  Fold MSE: 0.10294\n",
      "  Fold 31/50\n",
      "  Fold MSE: 0.00897\n",
      "  Fold 32/50\n",
      "  Fold MSE: 0.00422\n",
      "  Fold 33/50\n",
      "  Fold MSE: 0.00176\n",
      "  Fold 34/50\n",
      "  Fold MSE: 0.03428\n",
      "  Fold 35/50\n",
      "  Fold MSE: 0.00356\n",
      "  Fold 36/50\n",
      "  Fold MSE: 0.00063\n",
      "  Fold 37/50\n",
      "  Fold MSE: 3.98093\n",
      "  Fold 38/50\n",
      "  Fold MSE: 0.00172\n",
      "  Fold 39/50\n",
      "  Fold MSE: 0.29254\n",
      "  Fold 40/50\n",
      "  Fold MSE: 0.02065\n",
      "  Fold 41/50\n",
      "  Fold MSE: 0.30259\n",
      "  Fold 42/50\n",
      "  Fold MSE: 0.88235\n",
      "  Fold 43/50\n",
      "  Fold MSE: 0.00023\n",
      "  Fold 44/50\n",
      "  Fold MSE: 0.01132\n",
      "  Fold 45/50\n",
      "  Fold MSE: 0.02005\n",
      "  Fold 46/50\n",
      "  Fold MSE: 0.04329\n",
      "  Fold 47/50\n",
      "  Fold MSE: 0.34379\n",
      "  Fold 48/50\n",
      "  Fold MSE: 0.06474\n",
      "  Fold 49/50\n",
      "  Fold MSE: 0.01337\n",
      "  Fold 50/50\n",
      "  Fold MSE: 0.01466\n",
      "XGBoost_Optimized OOF MSE: 0.21269\n"
     ]
    }
   ],
   "source": [
    "# ==================== TREINAR ENSEMBLE FINAL ====================\n",
    "\n",
    "print(f\"\\nTreinando ensemble final com {len(hybrid_models)} modelos...\")\n",
    "\n",
    "n_splits = 50\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "oof_predictions = {name: np.zeros_like(y_train.values) for name in hybrid_models}\n",
    "test_predictions = {name: np.zeros((X_test.shape[0], len(target_cols))) for name in hybrid_models}\n",
    "\n",
    "for name, model in hybrid_models.items():\n",
    "    print(f\"\\nTreinando {name}...\")\n",
    "    fold_test_preds = []\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(X_train_scaled)):\n",
    "        print(f\"  Fold {fold+1}/{n_splits}\")\n",
    "        X_tr, X_val = X_train_scaled[train_idx], X_train_scaled[val_idx]\n",
    "        y_tr, y_val = y_train.values[train_idx], y_train.values[val_idx]\n",
    "\n",
    "        model.fit(X_tr, y_tr)\n",
    "        val_preds = model.predict(X_val)\n",
    "        oof_predictions[name][val_idx] = val_preds\n",
    "\n",
    "        fold_mse = mean_squared_error(y_val, val_preds)\n",
    "        print(f\"  Fold MSE: {fold_mse:.5f}\")\n",
    "\n",
    "        fold_test_preds.append(model.predict(X_test_scaled))\n",
    "\n",
    "    test_predictions[name] = np.mean(fold_test_preds, axis=0)\n",
    "    full_mse = mean_squared_error(y_train, oof_predictions[name])\n",
    "    print(f\"{name} OOF MSE: {full_mse:.5f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2806d2a6-7bb0-4631-b5be-c13281359ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Otimizando pesos do ensemble...\n"
     ]
    }
   ],
   "source": [
    "# ==================== ENSEMBLE COM PESOS OTIMIZADOS ====================\n",
    "\n",
    "print(\"\\nOtimizando pesos do ensemble...\")\n",
    "\n",
    "all_oof_preds = [oof_predictions[name] for name in hybrid_models]\n",
    "all_test_preds = [test_predictions[name] for name in hybrid_models]\n",
    "\n",
    "def ensemble_mse(weights, preds_list, y_true):\n",
    "    weighted_preds = np.zeros_like(y_true)\n",
    "    for i, w in enumerate(weights):\n",
    "        weighted_preds += w * preds_list[i]\n",
    "    return mean_squared_error(y_true, weighted_preds)\n",
    "\n",
    "optimal_weights = np.zeros((len(target_cols), len(hybrid_models)))\n",
    "\n",
    "for target_idx in range(len(target_cols)):\n",
    "    target_oof_preds = [preds[:, target_idx] for preds in all_oof_preds]\n",
    "\n",
    "    def target_objective(weights):\n",
    "        return ensemble_mse(weights, target_oof_preds, y_train.values[:, target_idx])\n",
    "\n",
    "    bounds = [(0, 1)] * len(hybrid_models)\n",
    "    result = differential_evolution(\n",
    "        target_objective,\n",
    "        bounds,\n",
    "        strategy='best1bin',\n",
    "        maxiter=50,  # Reduzido\n",
    "        popsize=10,  # Reduzido\n",
    "        tol=1e-4,\n",
    "        seed=42\n",
    "    )\n",
    "\n",
    "    weights = result.x\n",
    "    weights /= weights.sum()\n",
    "    optimal_weights[target_idx] = weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9a11416e-59af-4437-a861-494a1a72e233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Criando previsões finais...\n",
      "\n",
      "🎯 MSE Final do Ensemble: 0.19614\n",
      "📊 Comparação - Baseline: 0.22349\n",
      "📈 Melhoria: 12.24%\n"
     ]
    }
   ],
   "source": [
    "# ==================== PREVISÕES FINAIS ====================\n",
    "\n",
    "print(\"\\nCriando previsões finais...\")\n",
    "final_predictions = np.zeros((X_test_scaled.shape[0], len(target_cols)))\n",
    "\n",
    "for target_idx in range(len(target_cols)):\n",
    "    for model_idx, model_name in enumerate(hybrid_models):\n",
    "        weight = optimal_weights[target_idx, model_idx]\n",
    "        final_predictions[:, target_idx] += weight * all_test_preds[model_idx][:, target_idx]\n",
    "\n",
    "# Calcular MSE final do ensemble\n",
    "ensemble_oof = np.zeros_like(y_train.values)\n",
    "for target_idx in range(len(target_cols)):\n",
    "    for model_idx, model_name in enumerate(hybrid_models):\n",
    "        weight = optimal_weights[target_idx, model_idx]\n",
    "        ensemble_oof[:, target_idx] += weight * all_oof_preds[model_idx][:, target_idx]\n",
    "\n",
    "final_mse = mean_squared_error(y_train, ensemble_oof)\n",
    "print(f\"\\n🎯 MSE Final do Ensemble: {final_mse:.5f}\")\n",
    "print(f\"📊 Comparação - Baseline: {best_baseline_score:.5f}\")\n",
    "print(f\"📈 Melhoria: {((best_baseline_score - final_mse) / best_baseline_score * 100):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d18f1f31-ee6a-4e33-b9eb-c94015a9e8b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "💾 Submissão salva em: ../submissions/optuna_conservative_predictions.csv\n",
      "Salvando modelos e resultados...\n",
      "✅ Processo completo! Verifique o score - deve ser melhor que 0.8\n"
     ]
    }
   ],
   "source": [
    "# ==================== SUBMISSÃO ====================\n",
    "\n",
    "submission = pd.DataFrame(final_predictions, columns=[f\"target{i+1}\" for i in range(11)])\n",
    "submission.insert(0, 'Id', test_ids.values)\n",
    "submission.iloc[:, 1:] = submission.iloc[:, 1:].clip(lower=0)\n",
    "\n",
    "submission_file = '../submissions/optuna_conservative_predictions.csv'\n",
    "submission.to_csv(submission_file, index=False)\n",
    "print(f\"\\n💾 Submissão salva em: {submission_file}\")\n",
    "\n",
    "# ==================== SALVAR RESULTADOS ====================\n",
    "\n",
    "print(\"Salvando modelos e resultados...\")\n",
    "for name, model in hybrid_models.items():\n",
    "    joblib.dump(model, f'../models/{name}_conservative.pkl')\n",
    "joblib.dump(scaler, '../models/scaler_conservative.pkl')\n",
    "np.save('../models/optimal_weights_conservative.npy', optimal_weights)\n",
    "joblib.dump(study, '../models/optuna_study_conservative.pkl')\n",
    "\n",
    "# Relatório final\n",
    "with open('../results/optuna_conservative_report.txt', 'w') as f:\n",
    "    f.write(\"=== RELATÓRIO OTIMIZAÇÃO CONSERVADORA ===\\n\\n\")\n",
    "    f.write(f\"Melhor Baseline MSE: {best_baseline_score:.5f}\\n\")\n",
    "    f.write(f\"Melhor Optuna MSE: {study.best_value:.5f}\\n\")\n",
    "    f.write(f\"MSE Final Ensemble: {final_mse:.5f}\\n\")\n",
    "    f.write(f\"Melhoria total: {((best_baseline_score - final_mse) / best_baseline_score * 100):.2f}%\\n\\n\")\n",
    "    f.write(f\"Modelos no ensemble: {list(hybrid_models.keys())}\\n\")\n",
    "    f.write(f\"Pesos por target:\\n\")\n",
    "    for i, target in enumerate(target_cols):\n",
    "        f.write(f\"  {target}: {optimal_weights[i]}\\n\")\n",
    "\n",
    "print(\"✅ Processo completo! Verifique o score - deve ser melhor que 0.8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747cd108-227a-4cbb-b4e5-c7511783afa0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
